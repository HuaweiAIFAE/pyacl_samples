{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a91e58-1ee8-40ad-9832-ba257b046808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from src.preprocess import image_process, distance\n",
    "from src.model import Model, run_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9daf42b1-7522-4780-a5a8-fe06b5911348",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./facenet_data\"\n",
    "model_path = \"./models/facenet_tf.pb\"\n",
    "input_tensor_name = \"input:0\"\n",
    "output_tensor_name = \"embeddings:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a300b8-8ad6-4adb-94a5-c1d6e0cb345a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########NOW Start Preprocess!!!#########\n",
      "Image name: ann4\n",
      "WARNING:tensorflow:From /workspace/pyacl/pyacl_samples/TensorFlow/Online_FaceNet/src/preprocess.py:39: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "WARNING:tensorflow:From /workspace/pyacl/pyacl_samples/TensorFlow/Online_FaceNet/src/preprocess.py:43: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-25 06:33:35.693218: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2022-12-25 06:33:35.715150: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2022-12-25 06:33:35.720532: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ce0dbbe270 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-25 06:33:35.720559: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image name: ann3\n",
      "Image name: ann1\n",
      "Image name: rand1\n",
      "Image name: ann2\n",
      "images shape (5, 160, 160, 3) float32\n",
      "######## Read 5 images #########\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "print(\"########NOW Start Preprocess!!!#########\")\n",
    "images, images_count, image_name_list = image_process(image_path)\n",
    "print(\"images shape\", images.shape, images.dtype)\n",
    "print(\"######## Read %d images #########\" % (images_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a64864-17bb-4af2-843c-4472b2d99722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## NOW Start Batch!!! #########\n",
      "######## Object Created #########\n"
     ]
    }
   ],
   "source": [
    "###batch process\n",
    "print(\"######## NOW Start Batch!!! #########\")\n",
    "model = Model(model_path,input_tensor_name,output_tensor_name)\n",
    "print(\"######## Object Created #########\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1647a0af-42b0-4778-bc71-0125255ca7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## NOW Start inference!!! #########\n",
      "================== data (1, 160, 160, 3) float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-25 06:33:37.162279: W tf_adapter/util/npu_attrs.cc:148] [GePlugin] DEVICE_ID and ASCEND_DEVICE_ID is none, use default device id : 0, if set session_device_id, session_device_id has a higher priority\n",
      "2022-12-25 06:33:37.162318: W tf_adapter/util/ge_plugin.cc:124] [GePlugin] can not find Environment variable : JOB_ID\n",
      "2022-12-25 06:33:40.160832: I tf_adapter/kernels/geop_npu.cc:805] The model has been compiled on the Ascend AI processor, current graph id is: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== data (1, 160, 160, 3) float32\n",
      "================== data (1, 160, 160, 3) float32\n",
      "================== data (1, 160, 160, 3) float32\n",
      "================== data (1, 160, 160, 3) float32\n",
      "######## Inference Finished!!! #########\n",
      "Record 5 batch intervals\n",
      "In total spent [16.154643297195435, 0.004057884216308594, 0.003420114517211914, 0.003299713134765625, 0.0032913684844970703]\n"
     ]
    }
   ],
   "source": [
    "batch_output, batch_time = run_model(model, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be18563-deb8-4495-b5aa-2a8fca779f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Euclidean Distance\n",
      "Between ann4 and ann3: 1.449865\n",
      "Between ann4 and ann1: 0.745727\n",
      "Between ann4 and rand1: 0.862201\n",
      "Between ann4 and ann2: 0.673005\n",
      "Between ann3 and ann1: 1.094332\n",
      "Between ann3 and rand1: 1.361952\n",
      "Between ann3 and ann2: 1.074499\n",
      "Between ann1 and rand1: 0.824225\n",
      "Between ann1 and ann2: 0.211417\n",
      "Between rand1 and ann2: 0.998855\n",
      "\n",
      "==== Cosine Distance\n",
      "Between ann4 and ann3: 0.411306\n",
      "Between ann4 and ann1: 0.284271\n",
      "Between ann4 and rand1: 0.307429\n",
      "Between ann4 and ann2: 0.269119\n",
      "Between ann3 and ann1: 0.350377\n",
      "Between ann3 and rand1: 0.396618\n",
      "Between ann3 and ann2: 0.346836\n",
      "Between ann1 and rand1: 0.299984\n",
      "Between ann1 and ann2: 0.147690\n",
      "Between rand1 and ann2: 0.333158\n"
     ]
    }
   ],
   "source": [
    "assert len(image_name_list) == len(batch_output)\n",
    "\n",
    "print(\"==== Euclidean Distance\")\n",
    "for i in range(len(image_name_list)-1):\n",
    "    for j in range(i+1, len(image_name_list)):\n",
    "        print(\"Between %s and %s: %f\" % (image_name_list[i], image_name_list[j], distance(batch_output[i], batch_output[j])))\n",
    "print()\n",
    "print(\"==== Cosine Distance\")\n",
    "for i in range(len(image_name_list)-1):\n",
    "    for j in range(i+1, len(image_name_list)):\n",
    "        print(\"Between %s and %s: %f\" % (image_name_list[i], image_name_list[j], distance(batch_output[i], batch_output[j], distance_metric=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa8f01-685e-40d8-8220-624da7804d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
